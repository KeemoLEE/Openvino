{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "688a40c3-dfbc-46b3-9e8b-8e3158b314da",
   "metadata": {},
   "source": [
    "# 이미지 분류 AI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f65e1a53-5ebc-48d0-8a30-306663473385",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino as ov\n",
    "\n",
    "core=ov.Core()\n",
    "option=core.available_devices\n",
    "\n",
    "option"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e5b785-612a-42e2-940b-9b3718f79c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "core = ov.Core()\n",
    "model = core.read_model(model='./model/v3-small_224_1.0_float.xml')\n",
    "compiled_model = core.compile_model(model=model, device_name=\"CPU\")\n",
    "\n",
    "input_layer = compiled_model.input()\n",
    "output_layer = compiled_model.output()\n",
    "\n",
    "print(\"input_layer_shape:\", input_layer.shape)\n",
    "print(\"out_layer_shape:\", output_layer.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1240a1c2-865d-4b60-aa6a-e419959d5dcf",
   "metadata": {},
   "source": [
    "## 3. AI 추론 준비: 데이터 전처리 \n",
    "\n",
    "- 데이터 전처리: 새로 입력될 데이터 입력 형태 맞추기 <br>\n",
    "  input_layer_shape: [1,224,224,3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2caf4cdb-799b-4e16-a96a-c5a5f28a1645",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# AI 추론에 사용할 새로운 이미지 데이터 불러오기 \n",
    "\n",
    "#image = cv2.cvtColor(cv2.imread('./data/coco.jpg'), code=cv2.COLOR_BGR2RGB)\n",
    "image = cv2.cvtColor(cv2.imread('./data/fox.jpg'), code=cv2.COLOR_BGR2RGB)\n",
    "print(f\"image.shape:, {image.shape}\")\n",
    "# 입력된 새로운 이미지 데이터 크기를 AI 모델 입력 크기로 변환\n",
    "input_image = cv2.resize(src=image, dsize=(224, 224))\n",
    "print(f\"resize_input_image.shape:, {input_image.shape}\")\n",
    "# AI 모델 입력 형태에 맞게 차원 확장 하기\n",
    "input_image = np.expand_dims(input_image, 0)\n",
    "print(f\"expand_dims_input_image.shape:, {input_image.shape}\")\n",
    "#코코데이터를 그림으로 보'기\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(image);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c7161c0-0708-4768-a79b-614369c6a34b",
   "metadata": {},
   "source": [
    "## 4. AI 추론\n",
    "\n",
    "- input_image\n",
    "- compiled_model\n",
    "- output_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b5d440-91c0-4ae3-999c-5e12f9307d33",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_infer = compiled_model([input_image])[output_layer]\n",
    "result_index = np.argmax(result_infer) # 추론결과값중 가장 큰 값을 가지고 온다\n",
    "result_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdef616d-c896-4ae4-929f-da67c016ee50",
   "metadata": {},
   "outputs": [],
   "source": [
    "#추론결과값\n",
    "result_infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6841d00a-f939-43fd-ace2-60c000fb404d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_element_at_position(result_infer, row, col):\n",
    "    return result_infer[row, col]\n",
    "\n",
    "# 예시: 0번째 행, 2번째 열의 값을 출력\n",
    "print(get_element_at_position(result_infer, 0, 206))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d02e372-d0e3-4958-97ab-2ad4051d879d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_numbers(a, b):\n",
    "    if a > b:\n",
    "        return f\"{a} is greater than {b}\"\n",
    "    elif a < b:\n",
    "        return f\"{b} is greater than {a}\"\n",
    "    else:\n",
    "        return f\"{a} is equal to {b}\"\n",
    "\n",
    "# 숫자 비교\n",
    "num1 = 3.8589977e-05\n",
    "num2 = 0.77001953\n",
    "\n",
    "print(compare_numbers(num1, num2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51436f0e-5c13-4009-8bec-4a2e18f53583",
   "metadata": {},
   "source": [
    "* 참고\n",
    "3.8589977e-05: e-05는 10의 -5제곱을 의미.\n",
    "즉, 이 숫자는 3.8589977 × 10^-5로, 매우 작은 값. 소수점으로 표현하면 0.000038589977이 됩니다.\n",
    "거의 0에 가까움"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e0c7d29-4e60-4784-844b-eca6f2a42b4b",
   "metadata": {},
   "source": [
    "https://www.image-net.org/challenges/LSVRC/2012/browse-synsets.php"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4974a14e-0de8-47a5-9812-50b41611c95c",
   "metadata": {},
   "source": [
    "## 5. AI 추론 결과 출력\n",
    "\n",
    "- 추론 결과 해석\n",
    "- 추론 결과 출력\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43988c8c-ce21-48d8-8c26-d0942e0d4afc",
   "metadata": {},
   "source": [
    "아래 코드를 CHART GGPT를 이용해 해석해본다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3640da06-fcdf-4df9-9785-cd0886dae418",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "imagenet_filename = Path('./data/imagenet_2012.txt')\n",
    "#print(imagenet_filename)\n",
    "imagenet_classes = imagenet_filename.read_text().splitlines()\n",
    "#print(imagenet_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f0e23b-1723-4df3-b344-0aab5ee384bd",
   "metadata": {},
   "source": [
    "imagenet_classes 의 0번째에 background 를 넣어서 다시 구성함.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ddd6866-8d6f-4db0-9a42-248bb19873cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The model description states that for this model, class 0 is a background.\n",
    "# Therefore, a background must be added at the beginning of imagenet_classes.\n",
    "\n",
    "imagenet_classes = [\"background\"] + imagenet_classes\n",
    "#print(imagenet_classes)\n",
    "imagenet_classes[result_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c5f231-5303-4aa9-8b4a-062dda56d8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_classes[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8f3128-2120-454a-aa15-5902abf0d815",
   "metadata": {},
   "source": [
    "추론결과인 206번 내용을 확인함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc87d12-3aa0-488c-9f7c-d01f236d36e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagenet_classes[279]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d748d45-63ef-4b80-b968-861d89d2b3bb",
   "metadata": {},
   "source": [
    "# 배포: Gradio를 이용해 배포까지 한꺼번에 해보자\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8d32eff-5a67-4f93-a915-780ad3797e63",
   "metadata": {},
   "source": [
    "설치: pip install gradio \n",
    "https://www.gradio.app/guides/quickstart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bdde2c1-719e-4f94-9bfb-6c2d46b8f482",
   "metadata": {},
   "source": [
    "import gradio as gr\n",
    "\n",
    "def greet(name, intensity):\n",
    "    return \"Hello, \" + name + \"!\" * int(intensity)\n",
    "\n",
    "demo = gr.Interface(\n",
    "    fn=greet,\n",
    "    inputs=[\"text\", \"slider\"],\n",
    "    outputs=[\"text\"],\n",
    ")\n",
    "\n",
    "demo.launch()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa37b9df-35fa-4537-a316-f916a794bb09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openvino as ov\n",
    "import cv2\n",
    "import numpy as np\n",
    "import PIL\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46b8c900-f6ff-4152-b531-635bbaec22ed",
   "metadata": {},
   "source": [
    "## 데이터 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "53fd3291-131b-4f6c-add5-ef3b1b35cbe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and prepare the input/output layers\n",
    "core = ov.Core()\n",
    "model = core.read_model(model='model/v3-small_224_1.0_float.xml')\n",
    "compiled_model = core.compile_model(model=model, device_name=\"CPU\")\n",
    "input_layer = compiled_model.input(0)\n",
    "output_layer = compiled_model.output(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c00e72d8-341d-4f4c-9fcd-8ad5cbdab8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load ImageNet classes\n",
    "imagenet_filename = Path('data/imagenet_2012.txt')\n",
    "imagenet_classes = imagenet_filename.read_text().splitlines()\n",
    "imagenet_classes = [\"background\"] + imagenet_classes  # Include the background class"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "237fb237-561e-4d6d-8707-716f36c9042c",
   "metadata": {},
   "source": [
    "## 데이터 전처리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0cc42258-3854-4819-a7e3-feda4cee68b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image):\n",
    "    # Convert the PIL image to a NumPy array and resize to 224x224\n",
    "    image = np.array(image)  # Convert PIL image to numpy array\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)  # Convert RGB to BGR for OpenCV\n",
    "    input_image = cv2.resize(src=image, dsize=(224, 224))\n",
    "    input_image = np.expand_dims(input_image, axis=0)  # Add batch dimension\n",
    "    return input_image "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5665c4e-0533-4036-82ab-2b979b4be32e",
   "metadata": {},
   "source": [
    "## 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "236ff0fd-8c8a-41de-8e51-79ed0135cee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(image):\n",
    "    input_image = preprocess(image)  # Preprocess the image\n",
    "    result_infer = compiled_model([input_image])[output_layer]  # Perform inference\n",
    "    result_index = np.argmax(result_infer)  # Get the index of the highest score\n",
    "    \n",
    "    # Get the predicted class name\n",
    "    predicted_class = imagenet_classes[result_index]\n",
    "    return predicted_class  # Return just the predicted class name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e619f910-7c82-418f-948b-67bd2b24b9d7",
   "metadata": {},
   "source": [
    "## 배포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4853f488-6b5d-4293-bb7a-db8c87e4509f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gradio as gr\n",
    "\n",
    "# Set up the Gradio interface\n",
    "gr.Interface(fn=predict_image,\n",
    "             inputs=gr.Image(type=\"pil\"),\n",
    "             outputs=gr.Textbox(),  # Use Textbox to show the predicted class\n",
    "             examples=[\"./data/coco.jpg\"]).launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619b3891-67a3-4b11-aad6-8c7b904aada3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
